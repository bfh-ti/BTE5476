{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin: 0 auto 10px; height: 70px; border: 2px solid gray; border-radius: 6px;\">\n",
    "  <div style=\"float: left; margin: 5px 10px 5px 10px; \"><img src=\"img/bfh.jpg\" /></div>\n",
    "  <div style=\"float: right; margin: 20px 30px 0; font-size: 15pt; font-weight: bold; color: #98b7d2;\"><a href=\"https://moodle.bfh.ch/course/view.php?id=39255\" style=\"color: #98b7d2;\">BTE5476 - Project-Oriented Digital Signal Processing </a></div>\n",
    "</div>\n",
    "<div style=\"clear: both; font-size: 30pt; font-weight: bold; color: #64788b; margin-left: 30px;\">\n",
    "    Acoustic Reverberation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as sp\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 14, 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(file):\n",
    "    sf, x = wavfile.read(f'data/{file}.wav')\n",
    "    return sf, (x - np.mean(x)) / 32767.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Room Acoustics\n",
    "\n",
    "When a sound source is placed inside an enclosed space, the sound waves emanating from it will interact with the surrounding walls and will \"bounce around\" the room as a result of multiple specular and diffuse reflections. A listener within the space will thus hear a superposition of delayed and attenuated copies of the source signal and the resulting perceptual effect of this phenomenon is called _reverberation_. \n",
    "\n",
    "Virtually all of our listening experiences (either in real life or when listening to recorded music) are characterized by some reverberation, so much so that a completely \"dry\" signal (that is, a signal with no reverb such as a synthetic waveform heard using headphones) will sound quite innatural to our ears. \n",
    "\n",
    "In music production, especially in a studio setting where different instrumental parts are often recorded independently and later mixed together, it is common practice to record such tracks as \"dry\" as possible (eg. by placing microphones very close to the source) and only later add a global reveberation to the final mix. In this notebook we will look at the properties of a reverberant space and illustrate some of the methods that can be used to add realistic yet synthetic reverberation to an audio recoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT60\n",
    "\n",
    "<img width=\"300\" style=\"float: right; margin: 0 30px 0 30px;\" src=\"img/RT60.jpg\"> \n",
    "\n",
    "On a *macroscopic* level, the fundamental parameter of a reverberant space is the \"length\" of the reverb. We know from experience that large spaces (such as a cathedral) will sound very different than a small room or an open-air concert. The RT60 metric quantifies this intuition.\n",
    "\n",
    "**Reverberation Time 60**: time until the sound pressure level measured by the listened drops by 60 dB after the sound source stops\n",
    "\n",
    "| max RT60 |  room type  |  good for |\n",
    "|:---------:|-------------|------|\n",
    "| .3s | recording studio | no reverb |\n",
    "|  1s |  lecture hall | speech |\n",
    "| 1.5s |  concert hall | music |\n",
    "| > 2s |  cathedral |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Room Impulse Response (RIR)\n",
    "\n",
    "<img width=\"200\" style=\"float: right; margin: 0 30px 20px 30px;\" src=\"img/reflections.png\"> \n",
    "\n",
    "On a more detailed level, A reverberant room acts like a filter whose impulse response is dependent on the geometry of the enclosure, on the materials used for the walls and the objects in the space, and on the positions of both the sound source and of the listener. \n",
    "\n",
    "To understand the properties of a RIR, recall that the sound waves produced by the source will reach the listener multiple times:\n",
    " * via a direct path, if source and listener are in a direct line of sight\n",
    " * after being reflected once by a wall (first-order or \"early\" reflections)\n",
    " * after multiple reflections by different walls (high-order or late\" reflections)\n",
    "\n",
    "The number of reflections grows exponentially with increasing order and therefore the RIR becomes denser and denser towards its \"tail\"; at the same time, because of absorption losses, the amplitude of a reflection is an exponentially decreasing function of its order and so the typical time-domain envelope of a RIR is the one shown below:\n",
    "\n",
    "<img width=\"600\" style=\"display: block; margin: 40px auto;\" src=\"img/rir.png\"> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Reverb\n",
    "\n",
    "If the RIR is known, reverberation can be added to a dry audio signal via a simple convolution. RIRs can be obtained in various ways\n",
    "\n",
    " * via direct measurement\n",
    " * via room acoustics simulation methods\n",
    " * (implicitly) using synthetic reverb algorithms.\n",
    "\n",
    "Commercial reverb plug-ins generally offer a rich library of real-world and artificial RIRs.\n",
    "\n",
    "<img width=\"600\" style=\"display: block; margin: 20px auto;\" src=\"img/convrev.png\"> \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIR measurement\n",
    "\n",
    "<img width=\"200\" style=\"float: right; margin: 0 30px 20px 30px;\" src=\"img/icos.jpg\"> \n",
    "\n",
    "Source and microphone are placed in the chosen position; the source generates a test signal $x[n]$ and the microphone captures the reverberant sound\n",
    "\n",
    "$$ y[n] = (h\\ast x)[n] $$\n",
    "\n",
    "from which the RIR $h[n]$ can obtained via deconvolution. The typical source signals are\n",
    "\n",
    " * an impulse-like sound (starter gun, popping a balloon, etc.); if $x[n] \\approx \\delta[n]$ then $h[n] = y[n]$ and no deconvolution is necessary\n",
    " * a specific test signal with longer duration, designed to make deconvolution easy (eg. a chirp)\n",
    "\n",
    "Many complications:\n",
    " * approximating a true omnidirectional source (eg. using the icosahedral speaker shown in the figure)\n",
    " * reducing the impact of noise\n",
    " * account for the mechanics of human hearing (eg. binaural RIRs, with one microphone per ear)\n",
    "\n",
    "Here is an example of a measured RIR within a concert hall\n",
    "<img width=\"600\" style=\"display: block; margin: 0 auto;\" src=\"img/concerthall.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESS test signals\n",
    "\n",
    "A popular source signal for RIR measurements is the Exponentially Swept Sine, a chirp with instantaneous frequency increasing exponentially from $f_1$ Hz to $f_2$ Hz over $T$ seconds:\n",
    "\n",
    "$$\n",
    "    x[n] = \\sin\\left( 2\\pi\\frac{f_1 T}{R}(e^{\\frac{R}{TF_s}n} - 1)\\right), \\qquad n = 0, 1, \\ldots TF_s\n",
    "$$\n",
    "\n",
    "where $F_s$ is the sampling frequency and $R = \\ln(f_2 / f_1)$ is the sweep rate.\n",
    "\n",
    "The ESS signal makes deconvolution easy since $(x \\ast x_{inv})[n] \\approx K\\delta[n]$ for \n",
    "$$\n",
    "    x_{inv}[n] = x[-n] e^{-\\frac{R}{TF_s}n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ess(f1, f2, T, fs):\n",
    "    R = np.log(f2 / f1)\n",
    "    n = np.arange(0, int(T * fs))\n",
    "    \n",
    "    # ESS generation\n",
    "    x = np.sin((2 * np.pi * f1 * T / R) * (np.exp(n / fs * R / T) - 1))\n",
    "    \n",
    "    # Inverse signal\n",
    "    x_inv = x[::-1] * np.exp(-n / fs * R / T)\n",
    "\n",
    "    return x, x_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_inv = ess(10, 100, 3, 1000)\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.plot(x);\n",
    "plt.subplot(312)\n",
    "plt.plot(x_inv);\n",
    "plt.subplot(313)\n",
    "plt.plot(sp.fftconvolve(x, x_inv, mode='same'));\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(ess(200, 1000, 3, 8000)[0], rate=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Room Acoustics Simulation Methods\n",
    "\n",
    "In room acoustics, the goal is to determine the RIR from an abstract description of a room's geometry and physical properties. Several algorithmic approaches exist, with different strenghts and weaknesses and vastly different accuracy level and computational cost.\n",
    "\n",
    "<img width=\"600\" style=\"display: block; margin: 20px auto;\" src=\"img/methods.jpg\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Methods\n",
    "\n",
    "Geometric methods assume that sound propagates from the source in the form of straight rays rather than as a wave. These sound rays are reflected by the surrounding walls and then reflected again and again and, in principle, all the trajectories that ultimately reach the listener can be determined exactly using only elementary geometrical considerations.\n",
    "\n",
    "The accuracy of these methods decreases for low-frequency sounds, that is, when the wavelengths become commensurate with the room's dimensions and the propagation mechanism can no longer be properly modeled if wave phenomena are ignored. (In particular, sounds at lower frequencies easily propagate around an obstacle via edge diffraction whereas, using a ray-based model, they would appear completely blocked.)\n",
    "\n",
    "Below we will briefly describe two of the most common RIR geometric estimation methods; for a much more in-depth analysis that includes lots of excellent interactive demos, [this website](https://interactiveacoustics.info/) is an excellent resouce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-Source methods\n",
    "\n",
    "> An ideal specular reflection from a rigid surface can be represented by a mirror image source that is obtained by reflecting the sound source against the reflecting surface.\n",
    "\n",
    "<img width=\"200\" style=\"float: left; margin: 0 30px 20px 30px;\" src=\"img/firstorder.png\"> \n",
    "<img width=\"200\" style=\"float: left; margin: 0 50px 20px 30px;\" src=\"img/secondorder.png\"> \n",
    "\n",
    "\n",
    " * simple computations using law of reflection (billiard ball)\n",
    " * image sources are reflected too, leading to higher-order reflections\n",
    " * image sources do not depend on listener's position\n",
    " * ray paths are computed from listener to each image source: exact method (in theory)\n",
    " * each path of length $d$ contributes to the RIR via a scaling factor $\\propto 1/d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example for a 5th-order reflection:\n",
    "\n",
    "<img width=\"600\" style=\"display: block; margin: 20px auto;\" src=\"img/highorder.jpg\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues\n",
    " * numer of sources grows exponentially with max order\n",
    " * for polygonal rooms, image sources must be validate wrt listener position\n",
    " * difficult to model non-ideal reflections (absorption, scattering)\n",
    "\n",
    "Many efficient algorithmic implementations have been proposed that prune the image source tree before RIR computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray tracing\n",
    "\n",
    "<img width=\"200\" style=\"float: right; margin: 0 30px 20px 30px;\" src=\"img/diffuse.png\"> \n",
    "\n",
    "Similar to the image-source method but:\n",
    " * it uses a finite number of sound \"rays\" emanating in random directions from the source (stochastic method)\n",
    " * ray paths are tracked through multiple reflections\n",
    " * not all paths will \"hit\" the listener and listener must have nonzero \"volume\"\n",
    " * advantage: it can model diffuse reflections (surface scattering), important for RIR tail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wave-based Methods\n",
    "\n",
    "<img width=\"300\" style=\"float: right; margin: 30px 40px 20px 30px;\" src=\"img/wave.png\"> \n",
    "\n",
    "These methods focus on the wave nature of sound and its impact on reverberation:\n",
    " * diffusion and diffraction\n",
    " * material absorption\n",
    " * frequency-dependent room \"modes\" (eg. resonances or nulls)\n",
    "\n",
    "The wave equation (with boundary conditions set by the shape of the room) is solved numerically using finite element methods.\n",
    " * computationally expensive\n",
    " * cost proportional to max frequency\n",
    " * most useful for low frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid methods\n",
    "\n",
    "<img width=\"600\" style=\"display: block; margin: 20px auto;\" src=\"img/tradeoffs.jpg\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * [Pyroomacoustics](https://pyroomacoustics.readthedocs.io/en/pypi-release/index.html): developed at EPFL (in my lab), offers image source and some ray tracing. Demo notebook available\n",
    " * [Wayverb](https://reuk.github.io/wayverb/): very good introduction to room acoustics (most illustrations here were \"borrowed\" from the site) and very complete library offering all 3 methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverb simulation using DSP\n",
    "\n",
    "In many audio applications it's not really necessary to use a realistic RIR (either measured or synthesized) and we are only interested in making the sound less dry by adding some reverb with a definable RT60 value. In these cases a realistic reverberation can be simulated at an extremely low computational cost by using just a few low-order IIR filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echo vs reverberation\n",
    "\n",
    "Sound propagates in the air as a pressure wave and, if the wave encounters a hard surface, the discontinuity in the propagation medium causes a partial reflection. A listener hearing both the original sound and its reflection will experience:\n",
    " * a distinct echo if the two sounds are separated in time by at least 100ms\n",
    " * a reverb-like coloration otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slapback echo\n",
    "\n",
    "The so-called \"slapback\" echo, very popular in 1950s rockabilly music, uses a propagation delay of about 100ms, that is, a delay at the limit of echo perception that sounds a bit like reverb. It can be implemented via a simple FIR with transfer function\n",
    "$$\n",
    "    S(z) = (1-g) + gz^{-D}\n",
    "$$\n",
    "where $D \\approx \\lfloor F_s / 10 \\rfloor$; the parameter $g$, between 0 and 1, determines the amount of slapback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_sf, hb = load_wav('heartbreak')\n",
    "Audio(hb, rate = hb_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, D = 0.3, int(hb_sf * 0.10)\n",
    "h = np.r_[1-g, np.zeros(D), g]\n",
    "\n",
    "Audio(sp.lfilter(h, [1], hb), rate=hb_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tap delay echos (FIR)\n",
    "\n",
    "For a sound source within an enclosed space of reasonable size, the early reflections in the reverberation can be modeled as multiple short-time echos with varying amplitudes and delays.\n",
    "\n",
    "A finite number $M$ of overlapping echos can be generated via a so-called tap delay filter, namely, an FIR with transfer function\n",
    "\n",
    "$$\n",
    "    T(z) = c\\sum_{k=0}^{M} g_k z^{-D_k}\n",
    "$$\n",
    "where $D_k$ is the arrival delay of the $k$-th echo and $g_k$ the corresponding attenuation. This echo doesn't sound very natural because it stops abruptly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive echos (comb filters)\n",
    "\n",
    "Suppose a sound source is placed at equal distance from two parallel reflecting surfaces, and consider a listener in the same spot as the source; the sound will bounce back and forth and each reflection will reach the listener with a delay that is a multiple of the round-trip delay from source to surface. Because of the attenuation caused by the reflections and by propagation loss in air, each echo will be fainter than the previous.\n",
    "\n",
    "<img width=\"600\" style=\"float: right; margin: 0 0 30px 40px;\" src=\"img/comb.png\"> \n",
    "\n",
    "We can model this phenomenon with a simple first-order IIR filter where the feedback delay is equal to the propagation time between reflections and the feedback gain is less than one:\n",
    "\n",
    "$$\n",
    "    y[n] = x[n] + \\alpha y[n - D]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transfer function of the filter generating a recursive echo is \n",
    "$$\n",
    "    C(z) = \\frac{c}{1 - gz^{-D}}\n",
    "$$\n",
    "which is stable for $|g|<1$. The filter is often called a \"comb\" filter because its magnitude response exhibits a series of regularly-spaced peaks at frequencies multiples of $\\omega_0 = 2\\pi / D$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comb(delay: int, gain: float) -> [np.ndarray, np.ndarray]:\n",
    "    return [1], np.r_[1, np.zeros(int(delay) - 1), -gain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, g = 16, 0.7\n",
    "w, H = sp.freqz(*comb(D, g), 2048);\n",
    "plt.plot(w, np.abs(H));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The impulse response of a comb filter is an exponentially decaying sequence where only one sample every $D$ is nonzero:\n",
    "$$\n",
    "    c[n] = \\begin{cases} c\\,g^k & n = kD, k \\in \\mathbb{N} \\\\ 0 & \\mathrm{otherwise} \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(sp.lfilter(*comb(D, g), np.r_[1, np.zeros(100)]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf, piano = load_wav('piano')\n",
    "Audio(piano, rate=sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sp.lfilter(*comb(int(sf * 0.3), 0.7), piano), rate=sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allpass filters\n",
    "\n",
    "A filter with transfer function \n",
    "\n",
    "$$\n",
    "    A(z) = \\frac{z^{-D} - \\alpha}{1 - \\alpha z^{-D}}\n",
    "$$\n",
    "\n",
    "is called _allpass_ since it magnitude response is constant and equal to one, $|A(e^{j\\omega})| = 1$. By definition, an allpass filters doesn't change the spectral energy distribution of a signal; on the other hand, its nonlinear phase response will cause the input signal to \"spread out\" in the time domain, which can be used to simulate the diffuse reflections that contribute to the tail end of a RIR.\n",
    "\n",
    "<img width=\"600\" style=\"display: block; margin: 20px auto;\" src=\"img/allpass.png\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allpass(delay: int, alpha: float) -> [np.ndarray, np.ndarray]:\n",
    "    return np.r_[-alpha, np.zeros(int(delay - 1)), 1], np.r_[1, np.zeros(int(delay - 1)), -alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, alpha = 17, 0.7\n",
    "w, H = sp.freqz(*allpass(D, alpha), 2048);\n",
    "plt.plot(w, np.abs(H));\n",
    "plt.plot(w, np.angle(H));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The impulse response of a comb filter is also a spaced-out exponentially decaying sequence:\n",
    "$$\n",
    "    a[n] = \\begin{cases}\n",
    "        0 & n < 0\\\\\n",
    "        -\\alpha & n = 0 \\\\\n",
    "        \\alpha^k (1-\\alpha^2) & n = kD \\\\\n",
    "        0 & \\text{otherwise}\n",
    "        \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(sp.lfilter(*allpass(D, g), np.r_[1, np.zeros(200)]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load an impulse-like audio excerpt and see how an allpass filter can spread out the peak in time without affecting the acoustic properties too much:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf, snare = load_wav('snare')\n",
    "snare = snare[:10000]\n",
    "\n",
    "D, alpha = 210, 0.7\n",
    "ap_snare = sp.lfilter(*allpass(D, alpha), snare);\n",
    "\n",
    "plt.plot(snare);\n",
    "plt.plot(ap_snare);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(snare, rate=sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(ap_snare, rate=sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic reverberators\n",
    "\n",
    "Comb and allpass filters are the building blocks used by the two well-known reverb simulators described below. Both methods use a bank of comb filters to simulate early reflections and one or more allpass filters to produce the dense tail of the impulse response due to diffusion. \n",
    "\n",
    "The delays of the comb filters are a function of the size of the room; to increase the density of the early reflections, multiple comb filters are used in parallel making sure the delay values are coprime so that the nonzero values of their impulse responses do not overlap in time. The delays of the allpass filters are chosen so that so that the overall impulse response of the reverberator exhibits the desired RT60 value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting the delays\n",
    "\n",
    "Many implementations of the reverberation algorithms can be found in the literature, with delay and gain values been carefully selected to be coprime and to produce a good reverberation quality. The delay values of each implementation are specified in samples and they therefore assume a specific sampling rate for the input signals. When adapting one of these designs to a differnt rate, we need to scale the delay values appropriately while trying to preserve coprimality. \n",
    "\n",
    "In the examples below this is achieved by rounding the rate-adjusted delay values to the nearest prime number; the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_primes(values, margin=1.5):\n",
    "    values = np.array(values).astype(int)\n",
    "    limit = int(np.max(values) * margin)\n",
    "\n",
    "    # mark all prime numbers up to the limit using Eratosthenes sieve\n",
    "    a = np.ones(limit).astype(bool)\n",
    "    a[1] = a[::2] = False\n",
    "    for i in range(3, int(np.sqrt(limit)) + 1):\n",
    "        if a[i]:\n",
    "            a[i*i::2*i] = False\n",
    "    if not np.any(a[np.max(values):]):\n",
    "        raise 'increase the top margin for prime search'\n",
    "\n",
    "    vp = np.zeros_like(values)\n",
    "    for ix, v in enumerate(values):\n",
    "        # find neighboring primes (smaller and greater) and keep the closest\n",
    "        vs = vg = v\n",
    "        while not a[vs]:\n",
    "            vs -= 1\n",
    "        while not a[vg]:\n",
    "            vg += 1\n",
    "        vp[ix] = vs if np.abs(v - vs) < np.abs(v - vg) else vg   \n",
    "        \n",
    "    return vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_primes([3239, 3073, 3941, 4321])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schroeder's reverberator\n",
    "\n",
    "[Schroeder's algorithm](https://ieeexplore.ieee.org/document/1166351), published in 1961, uses a bank of four comb filters with coprime delays for the early reflections and a cascade of three allpass of increasing order for the diffuse reflections. The original audio (the \"dry\" signal) and the output of the reverberator (the \"wet\" signal) can be mixed in different proportions to choose the final amount of added reverb\n",
    "\n",
    "<img width=\"600\" style=\"display: block; margin: 0px auto;\" src=\"img/schroeder.png\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schroeder(x, sf, wet=0.2):\n",
    "    # delays and gains for allpass and comb filters; these produce a reverb with RT60 of about 1 second\n",
    "    #  and were proposed by John Chowning (CCRMA, Stanford)\n",
    "    AP = np.array([[347, 113, 37], [0.7, 0.7, 0.7]])\n",
    "    CF = np.array([[1687, 1601, 2053, 2251], [0.773, 0.802, 0.753, 0.733]])\n",
    "    DESIGN_SF = 25000  # filter delays are relative to this sampling rate\n",
    "\n",
    "    # recompute delays wrt current sampling rate\n",
    "    AP[0] = closest_primes(AP[0] * sf / DESIGN_SF)\n",
    "    CF[0] = closest_primes(CF[0] * sf / DESIGN_SF)\n",
    "\n",
    "    # comb filters\n",
    "    y = np.zeros(len(x))\n",
    "    for n in range(len(CF[0])):\n",
    "        y += sp.lfilter(*comb(CF[0][n], CF[1][n]), x)\n",
    "\n",
    "    # allpass\n",
    "    for n in range(len(AP[0])):\n",
    "        y = sp.lfilter(*allpass(AP[0][n], AP[1][n]), y)\n",
    "    \n",
    "    return wet * y + (1 - wet) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(schroeder(np.r_[1, np.zeros(25000)], 25000, wet=0.5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test audio file; add silence at the end to hear the reverberation's decay\n",
    "\n",
    "audio_sf, audio = load_wav('guitar')\n",
    "audio = np.r_[audio, np.zeros(audio_sf)]\n",
    "Audio(audio, rate=audio_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(schroeder(audio, audio_sf), rate=audio_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moorer's reverberator\n",
    "\n",
    "Moorer's algorithm, published in 1979, creates a finite number of early reflections using a FIR tap delay; this \"early\" reverb is then processed by a structure very similar to Schroeder's reverberator and the result (the \"late\" reverberation) is delayed and appended after the \"early\" portion. The resulting impulse response has a clearer early/late structure and is less dense than in the previous case.\n",
    "\n",
    "<img width=\"600\" style=\"display: block; margin: 0px auto;\" src=\"img/moorer.png\"> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moorer(x, sf, wet=0.1):\n",
    "    AP = np.array([[225], [0.7]])\n",
    "    CF = np.array([[1801, 1478, 2011, 2123], [0.805, 0.827, 0.783, 0.764]])\n",
    "    TD = np.array([[40, 70, 149], [.4, .3, .2]])\n",
    "    DESIGN_SF = 44100  \n",
    "\n",
    "    AP[0] = closest_primes(AP[0] * sf / DESIGN_SF)\n",
    "    CF[0] = closest_primes(CF[0] * sf / DESIGN_SF)\n",
    "    TD[0] = closest_primes(TD[0] * sf / DESIGN_SF)\n",
    "\n",
    "    td_max = int(max(TD[0])) + 1\n",
    "    h = np.zeros(td_max)\n",
    "    for k in range(len(TD[0])):\n",
    "        h[int(TD[0][k])] = TD[1][k]\n",
    "    early = sp.lfilter(h, [1], x)\n",
    "    \n",
    "    y = np.zeros(len(x))\n",
    "    for k in range(len(CF[0])):\n",
    "        y += sp.lfilter(*comb(CF[0][k], CF[1][k]), x)\n",
    "    \n",
    "    # Allpass stage\n",
    "    y = sp.lfilter(*allpass(AP[0][0], AP[1][0]), y)\n",
    "    \n",
    "    # Delay\n",
    "    late = np.r_[np.zeros(td_max), y][:len(early)]\n",
    "    \n",
    "    return wet * (early + late) + (1 - wet) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(moorer(np.r_[1, np.zeros(44100)], 44100, wet=0.3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio, rate=audio_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(moorer(audio, audio_sf, wet=0.5), rate=audio_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(moorer(hb, hb_sf, wet=.3), rate=hb_sf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
