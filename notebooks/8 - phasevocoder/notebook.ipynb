{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"margin: 0 auto 10px; height: 70px; border: 2px solid gray; border-radius: 6px;\">\n",
    "  <div style=\"float: left; margin: 5px 10px 5px 10px; \"><img src=\"img/bfh.jpg\" /></div>\n",
    "  <div style=\"float: right; margin: 20px 30px 0; font-size: 15pt; font-weight: bold; color: #98b7d2;\"><a href=\"https://moodle.bfh.ch/course/view.php?id=39255\" style=\"color: #98b7d2;\">BTE5476 - Project-Oriented Digital Signal Processing </a></div>\n",
    "</div>\n",
    "<div style=\"clear: both; font-size: 30pt; font-weight: bold; color: #64788b; margin-left: 30px;\">\n",
    "    Phase vocoder\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as sp\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 14, 4 \n",
    "plt.rcParams['image.cmap'] = 'tab10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def multiplay(clips, sf, title=None):\n",
    "    outs = [widgets.Output() for c in clips]\n",
    "    for ix, item in enumerate(clips):\n",
    "        with outs[ix]:\n",
    "            print(title[ix] if title is not None else \"\")\n",
    "            display(Audio(item, rate=sf, normalize=True))\n",
    "    return widgets.HBox(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# pre-load audio samples in a dictionary\n",
    "audio, audio_sf = {}, None\n",
    "for file in ['speech', 'music', 'cymbal', 'clarinet'] :\n",
    "    sf, x = wavfile.read(f'data/{file}.wav')\n",
    "    if audio_sf is None:\n",
    "        audio_sf = sf\n",
    "    else:\n",
    "        assert sf == audio_sf, 'notebook requires sampling rates for all audio samples to be the same'\n",
    "    audio[file] = (x - np.mean(x)) / 32767.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms2n(ms, sf):\n",
    "    return int(float(sf) * ms / 1000.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time scaling with granular synthesis\n",
    "\n",
    "<img width=\"800\" style=\"margin: 10px;\" src=\"img/ola.png\">\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "For a scaling factor $\\alpha$: \n",
    "\n",
    " * choose a grain size of $N$ samples (typically 40 ms for speech, 100 ms for music) \n",
    " * choose the grain overlap factor $K$ and obtain the COLA stride $S$ \n",
    " * $S$ is known as the _sythesis hop size_, since output grains will be spaced $S$ samples apart\n",
    " * the _analysis hop size_ is $S_a = \\lfloor S \\alpha \\rfloor$ \n",
    " * iterate over $k = 0, 1, \\ldots$:\n",
    "     * extract a grain from the input as $g_k[n] = x_i[n-kS_a]$  \n",
    "     * add $w[n-kS]g_k[n-kS]$ to the output signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hann_cola(N: int, K=2) -> (np.ndarray, int, int):\n",
    "    if K <= 1:\n",
    "        return np.ones(N), N, N\n",
    "    S = N // K\n",
    "    N = K * S + 1\n",
    "    win = (2 / K) * np.sin(np.pi * np.arange(0, N) / (N-1)) ** 2\n",
    "    return win, N, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def timescale_gs(x, alpha, grain_size, K=2):\n",
    "    win, N, S = hann_cola(grain_size, K)\n",
    "    y = np.zeros(int(len(x) / alpha + 1))\n",
    "    a_hop, s_hop = int(S * alpha), S \n",
    "    n, m = 0, 0\n",
    "    while n < len(x) - N and m < len(y) - N:\n",
    "        y[m:m+N] += x[n:n+N] * win\n",
    "        n += a_hop\n",
    "        m += s_hop\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "factors = [1.4, 0.8]\n",
    "\n",
    "for file, gs_ms in [('speech', 120), ('music', 200)]:\n",
    "    gs = ms2n(gs_ms, audio_sf)\n",
    "    display(multiplay(\n",
    "        [audio[file], *(timescale_gs(audio[file], a, gs, K=3) for a in factors)], \n",
    "        audio_sf, \n",
    "        [f'{file} sample', *('slower' if a < 1 else 'faster' for a in factors)] \n",
    "    ))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The technique works well to speed up speech but slowed down speech still has clicking artefacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The problem with \"simple\" granular synthesis\n",
    "\n",
    "Granular synthesis seems to work well on non pitched sounds but not so well on sustained periodic sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.75\n",
    "\n",
    "for file, gs_ms in [('cymbal', 80), ('clarinet', 100)]:\n",
    "    gs = ms2n(gs_ms, audio_sf)\n",
    "    display(multiplay(\n",
    "        [audio[file], timescale_gs(audio[file], alpha, gs, K=3)], \n",
    "        audio_sf, \n",
    "        [f'{file}', 'time-stretched'] \n",
    "    ))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It will be easier to investigate the problem if we use a simple sinusoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.sin(2 * np.pi * (110 / audio_sf) * np.arange(0, audio_sf))\n",
    "s = slice(1000, 3000)\n",
    "plt.plot(x[s]);\n",
    "Audio(x, rate=audio_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gs = ms2n(40, audio_sf)\n",
    "x_ts = timescale_gs(x, alpha, gs)\n",
    "plt.plot(x_ts[s])\n",
    "Audio(x_ts, rate=audio_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The reason for the strange waveform becomes evident if we set the grain overlap to zero: phase jumps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(timescale_gs(x, alpha, gs, K=0)[s])\n",
    "for n in range(gs - s.start % gs, s.stop - s.start, gs):\n",
    "    plt.axvline(n, color='red', alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Phase jumps\n",
    "\n",
    "The $k$-th grain extracted from the input is\n",
    "$$\n",
    "    g_{k}[n] = x_i[kS_a + n]\n",
    "$$\n",
    "which, for $x_i[n] = \\sin(\\omega_0 n)$, becomes\n",
    "$$\n",
    "    g_{k}[n] = \\sin(\\omega_0 n + k \\omega_0  S_a  ).\n",
    "$$\n",
    "The phase difference at the beginning of two consecutive grains is \n",
    "$$\n",
    "    \\Delta_k = \\angle g_{k}[0] - \\angle  g_{k-1}[0] = \\omega_0 S_a\n",
    "$$\n",
    "When the grains are merged in the output, however, they will be spaced $S = S_a/\\alpha$ samples apart and so, to avoid phase discontinuities, their phase difference should be\n",
    "$$\n",
    "    \\Delta'_k = \\angle g_{k-1}[S] - \\angle  g_{k-1}[0] = \\omega_0 S = \\Delta_k/ \\alpha\n",
    "$$\n",
    "\n",
    "Of course, if the input was a sinusoid of known frequency and fixed amplitude, we would not need granular synthesis at all. For arbitrary signals, nevertheless, we can use the same approach if we consider the DFT of each grain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Phase vocoder\n",
    "\n",
    "If $G_k[m]$ are the $N$ DFT coefficients of a grain, using polar coordinates we can write $G_k[m] = A_k[m]e^{j\\varphi_k[m]}$. With this we can express the grain as the sum of $N$ sinusoidal signals using the inverse DFT formula:\n",
    "$$\n",
    "    g_k[n] = \\sum_{m=0}^{N-1} A_k[m]\\, \\mathrm{exp}[j(\\omega_m n + \\varphi_k[m])], \\quad \\omega_m = \\frac{2\\pi}{N}m.\n",
    "$$\n",
    "Within a grain, the phase of each component increases by $\\omega_m$ per sample, so that the expected phase after $S_a$ samples is \n",
    "$$\n",
    "    \\gamma_{k,m}[S_a] = \\omega_m S_a + \\varphi_{k}[m].\n",
    "$$\n",
    "If the signal contained only one or more $N$-periodic sinusoids, the initial phases $\\varphi_k[m]$ of each grain $k$ would be exactly equal to $\\gamma_{k-1,m}[S_a]$; in all other cases however, (which is to say, always), this will not be the case. The phase offset between successive grains as the difference between the initial phase of the next grain and the expected phase of the previous grain at $n=S_a$:\n",
    "$$\n",
    "    \\Delta_{k, m} = \\varphi_{k}[m] - \\gamma_{k-1,m}[S_a] =  \\varphi_{k}[m] - \\varphi_{k-1}[m] - \\omega_m S_a,\n",
    "$$\n",
    "Importantly, the phase offset must be \"wrapped\" over the $[-\\pi, \\pi]$ interval. \n",
    "\n",
    "To create the time-stretched signal, before being merged into the output each grain is resynthesized from a modified set of DFT coefficients $G'_k[m] = A_k[m]e^{j\\varphi'_k[m]}$; the amplitude remains the same but the phase is \n",
    "$$\n",
    "    \\varphi'_k[m] = \\varphi'_{k-1}[m] + \\omega_m S + \\Delta_{k,m}/\\alpha.\n",
    "$$\n",
    "In other words, starting from an initial output phase $\\varphi'_0[m]$, the phase for each component is incremented by the expected amount $\\omega_m S$ plus the phase offset normalized by the time stretch factor $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "Consider two segments of an audio signal and their superposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pv(x, N, Sa, S):\n",
    "    x1, x2 = x[:N], x[Sa:Sa+N]\n",
    "    X1, X2 = np.fft.fft(x1), np.fft.fft(x2)\n",
    "\n",
    "    w = 2 * np.pi / N * np.arange(N)\n",
    "    \n",
    "    Delta = np.angle(X2) - np.angle(X1) - w * Sa\n",
    "    Delta = Delta - 2 * np.pi * np.round(Delta / 2 / np.pi)\n",
    "    \n",
    "    g2 = np.real(np.fft.ifft(np.abs(X2) * np.exp(1j * (np.angle(X1) + w * S + Delta * S / Sa))))\n",
    "    \n",
    "    plt.plot(x1)\n",
    "    plt.plot(np.arange(S,S+N), x2)    \n",
    "    plt.figure()\n",
    "    plt.plot(x1)\n",
    "    plt.plot(np.arange(S,S+N), g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pv(audio['music'][65000:], 1000, 120, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementation\n",
    "\n",
    "Changing the phase of a sinusoidal componet is equivalent to a circular shift; since the first and the last samples in a grain have most likely different values, it's important to use a tapering window before computing each DFT as well. With this, here is a full implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timescale_gs_pv(x, alpha, grain_size, K=4):\n",
    "    win, N, S = hann_cola(grain_size, K)\n",
    "    a_hop, s_hop = int(S * alpha), S \n",
    "    \n",
    "    wk = 2 * np.pi * np.arange(0, N) / N\n",
    "    phase = prev_phase = np.angle(np.fft.fft(x[:N]))\n",
    "\n",
    "    def wrap_angle(w):\n",
    "        return w - 2 * np.pi * np.round(w / 2 / np.pi)\n",
    "    \n",
    "    y = np.zeros(int(len(x) / alpha + 1))    \n",
    "    n, m = 0, 0\n",
    "    while n < len(x) - N and m < len(y) - N:\n",
    "        grain_fft = np.fft.fft(win * x[n:n + N])\n",
    "        grain_phase = np.angle(grain_fft)\n",
    "        phase_delta = wrap_angle(grain_phase - prev_phase - a_hop * wk)\n",
    "        prev_phase = grain_phase\n",
    "        phase = wrap_angle(phase + s_hop * (wk + phase_delta / a_hop))\n",
    "        grain = np.real(np.fft.ifft(np.abs(grain_fft) * np.exp(1j * phase)))\n",
    "        y[m:m+N] += grain * win\n",
    "        n += a_hop\n",
    "        m += s_hop\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can now test with the sinusoidal signal again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts_pv = timescale_gs_pv(x, alpha, gs)\n",
    "plt.plot(x_ts_pv[s])\n",
    "multiplay([x, x_ts, x_ts_pv], audio_sf, title=['test sinusoid', 'stretched with GS', 'stretched with GS-PV'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, gs_ms in [('speech', 80), ('music', 200)]:\n",
    "    gs = ms2n(gs_ms, audio_sf)\n",
    "    display(multiplay(\n",
    "        [ audio[file], *( ts(audio[file], alpha, gs, K=3) for ts in [timescale_gs, timescale_gs_pv] ) ], \n",
    "        audio_sf, \n",
    "        [f'{file} sample', *( f'slower ({algo})' for algo in ['GS', 'GS_PV'] ) ]\n",
    "    ))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitch shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def resample(x, alpha):\n",
    "    N = len(x)\n",
    "    y, m = np.zeros(int(N / alpha + 0.5)), 0\n",
    "    while True:\n",
    "        t = m * alpha \n",
    "        n = int(np.floor(t))\n",
    "        if n < N - 1:\n",
    "            y[m] = (n + 1 - t) * x[n] + (t - n) * x[n + 1] \n",
    "            m += 1\n",
    "        else:\n",
    "            break\n",
    "    return y[:m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semitone = 2 ** (1.0 / 12)\n",
    "shift = 3\n",
    "alpha = semitone ** shift\n",
    "\n",
    "for file, gs_ms in [('speech', 80), ('music', 200)]:\n",
    "    gs = ms2n(gs_ms, audio_sf)\n",
    "    display(multiplay(\n",
    "        [ audio[file], *( resample(ts(audio[file], alpha, gs, K=3), 1/alpha) for ts in [timescale_gs, timescale_gs_pv] ) ], \n",
    "        audio_sf, \n",
    "        [f'{file} sample', *( f'slower ({algo})' for algo in ['GS', 'GS_PV'] ) ]\n",
    "    ))    "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
