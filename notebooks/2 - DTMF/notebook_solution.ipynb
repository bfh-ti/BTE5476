{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<div style=\"margin: 0 auto 10px; height: 70px; border: 2px solid gray; border-radius: 6px;\">\n",
    "  <div style=\"float: left; margin: 5px 10px 5px 10px; \"><img src=\"img/bfh.jpg\" /></div>\n",
    "  <div style=\"float: right; margin: 20px 30px 0; font-size: 15pt; font-weight: bold; color: #98b7d2;\"><a href=\"https://moodle.bfh.ch/course/view.php?id=39255\" style=\"color: #98b7d2;\">BTE5476 - Project-Oriented Digital Signal Processing </a></div>\n",
    "</div>\n",
    "<div style=\"clear: both; font-size: 30pt; font-weight: bold; color: #64788b; margin-left: 30px;\">\n",
    "    DTMF Signaling\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as sp\n",
    "import IPython\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (9,2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "<div style=\"float: right; margin: 10px;\"><img src=\"img/phone.jpg\" width=\"250\"></div>\n",
    "\n",
    "DTMF (Dual-Tone Multi-Frequency) is a signaling protocol used to transmit simple numeric information over the frequency band provided by analog telephone lines, that is, between 300 Hz and 3400 Hz. When you use the keypad of an analog phone such as the one shown on the right, the sequence of dialed digits is transmitted to the phone company's switches in the form of audible _dial tones_. Today, cell phones and office phones are directly connected to digital networks and therefore no longer use DTMF for dialing. But DTMF is still frequently used in automated attendant systems (i.e., those phone menus where you are told to \"press 1 to talk to customer service\" etc.)\n",
    "\n",
    "\n",
    "## DTMF specifications\n",
    "\n",
    "In DTMF the phone's keypad is arranged in a $4\\times 3$ grid and each key is associated to a unique *pair* frequencies, as shown by this table:\n",
    "\n",
    "\n",
    "|            | **1209 Hz** | **1336 Hz** | **1477 Hz** |\n",
    "|------------|:-----------:|:-----------:|:-----------:|\n",
    "| **697 Hz** |      1      |      2      |      3      |\n",
    "| **770 Hz** |      4      |      5      |      6      |\n",
    "| **852 Hz** |      7      |      8      |      9      |\n",
    "| **941 Hz** |      *      |      0      |      #      |\n",
    "\n",
    "\n",
    "When a key is pressed, two oscillators operating at the frequencies associated to the key send their output over the phone line. For instance, if the digit '1' is pressed, the oscillators will produce the following continuous-time signal\n",
    "$$\n",
    "    x(t) = \\sin(2\\pi\\cdot 1209\\cdot t) + \\sin(2\\pi\\cdot697\\cdot t)\n",
    "$$\n",
    "\n",
    "When dialing a multi-digit number, successive dial tones must be separated by a silent gap; although the official standard does not set standard timings, a DTMF receiver should be designed according to the following specifications:\n",
    " * valid dial tones can be as short as 40ms \n",
    " * the silent gap between tones can also be as short as 40ms\n",
    " * actual tone frequencies can deviate up to $\\pm 1.5\\%$ from their nominal values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Digital DTMF\n",
    "\n",
    "DTMF was developed in the late 1950s and the first commercial DTMF phones hit the market in the 1960s. At the time, the system was implemented using analog hardware and the various frequencies were generated by a set of individual electronic oscillators.\n",
    "\n",
    "<div style=\"float: left; margin: 0px;\"><img src=\"img/mt8870.jpg\" width=\"150\"></div>\n",
    "\n",
    "Obviously this is no longer the case and today DTMF signals are generated and decoded by dedicated (and extremely inexpensive) [DSP chips](https://pdf.datasheetcatalog.com/datasheets/228/268107_DS.pdf). In this notebook we will implement our own digital DTMF algorithms but, before anything else, let's review the relationship between the DTMF frequency values in Hz as specified by the standard and the digital frequencies that we will need to use in discrete time. This is relatively straightforward even without any formal knowledge of sampling and interpolation since all the signals involved are pure sinusoids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Digital to analog \n",
    "\n",
    "A digital-to-analog (D/A) converter, such as the soundcard in your PC, creates its analog output by interpolating the incoming digital samples at a rate of $F_s$ samples per second; this rate is the \"clock\" of D/A converter and, although it is an _interpolation_ rate, it is usually referred to as the _sampling rate_ or sampling _frequency_ of the system, using the same term that we use for an analog-to-digital converter.\n",
    "\n",
    "When a soundcard with interpolation rate $F_s$ \"plays\" a discrete-time sequence of the form $x[n] = \\cos(\\omega_0 n)$ (that is, a discrete-time sinusoid with digital frequency $\\omega_0 \\in [-\\pi, \\pi]$), it outputs the continuous-time sinusoid $x(t) = \\cos(2\\pi f_0 t)$ where\n",
    "\n",
    "$$\n",
    "    f_0 = \\frac{\\omega_0}{2\\pi}F_s. \\tag{1}\n",
    "$$\n",
    "\n",
    "This means that the analog frequency of the output depends _both_ on the frequency of the discrete-time sinusoid _and_ on the interpolation rate of the soundcard, which is usually a design parameter. In general, we want to keep all sampling rates as low as possible since the power consumption of an D/A chip is approximately proportional to $F_s^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As an example, here you can listen to how the pitch changes when the _same_ discrete-time sinusoid is played by the soundcard at different interpolation rates (and note how the duration of the audio also changes, obviously): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = 2 * np.pi * 0.05 \n",
    "x = np.sin(w * np.arange(0, 8000))\n",
    "\n",
    "for Fs in [8000, 16000, 4000]:\n",
    "    print(f'Using an interpolation rate of {Fs} samples per second:')\n",
    "    display(IPython.display.Audio(x, rate=Fs, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Exercise: minimal rate.** What is the minimal interpolation rate required by to implement a digital DTMF transmitter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "**SOLUTION:** \n",
    "\n",
    "Since the fastest possible digital frequency is $\\omega = \\pi$, as per eq. (1) the highest frequency that an D/A can generate is $F_s/2$. The largest frequency value in the DTMF table is 1477 Hz, and therefore we need \n",
    "$$\n",
    "    F_s > 2954.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Analog to digital\n",
    "\n",
    "The soundcard in your PC also works as an analog-to-digital (A/D) converter: it records an incoming audio signal by measuring (that is, by _sampling_) its amplitude $F_s$ times per second. \n",
    "\n",
    "If the input is a sinusoid of the form $x(t) = \\sin(2\\pi f_0 t)$ the resulting discrete-time signal will be \n",
    "\n",
    "$$\n",
    "    x[n] = \\sin(\\omega_0 n) \\qquad \\text{with} \\qquad \\omega_0 = 2\\pi\\frac{f_0}{F_s}.\n",
    "$$\n",
    "\n",
    "As long as the a sampling frequency is larger than _twice_ the frequency of the input sinusoid, the sequence of samples is a perfect representation of the analog waveform in the sense that $x[n]$ can be interpolated back into $x(t)$ _exactly_ by a D/A converter also operating at $F_s$ samples per second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Exercise: aliasing.** Consider D/A converter connected in cascade to a A/D converter; both converters operate at the same rate $F_s$. Assume that the input to the cascade is the signal $x(t) = \\sin(2\\pi f_0 t)$ with $f_0 = 1.6F_s$.\n",
    "\n",
    "What is the analog signal at the output of the cascade?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "source": [
    "**SOLUTION:** \n",
    "\n",
    "The A/D will produce a discrete time sinusoid $x[n] = \\sin(\\omega_0 n)$ whose digital frequency is\n",
    "$$\n",
    "    \\omega_0 = 2\\pi\\frac{f_0}{F_s} = 3.2\\pi.\n",
    "$$\n",
    "Since $\\omega_0 > 2\\pi$ we can use trigonometry to bring the frequency in the $[-\\pi,\\pi]$ interval:\n",
    "$$\n",
    "    x[n] = \\sin(3.2\\pi n) = \\sin(1.2\\pi n + 2\\pi n) = \\sin(1.2\\pi n)\n",
    "$$\n",
    "When this signal enters the D/A, it produces an analog sinusoid with frequency\n",
    "$$\n",
    "    f'_0 = \\frac{1.2\\pi}{2\\pi}F_s = 0.6F_s,\n",
    "$$\n",
    "that is, the original frequency has been aliased to a completely different value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Final design parameter\n",
    "\n",
    "Although in theory we could use a lower value, in the rest of the notebook we will use $F_s = 8000$:\n",
    " * since the telephone channel is \"natuarally\" bandlimited to 4000 Hz, with a sampling frequency of 8 kHz no additional anti-aliasing filter is needed\n",
    " * in most soundcards, this is the lowest available sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Fs = 8000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# The encoder\n",
    "\n",
    "In the next exercise, you task will be to implement a DTMF encoder as a Python function: the function takes a string of key values as input and returns their DTMF encoding as discrete-time audio signal that can be played at a rate of $F_s$ samples/second.\n",
    "\n",
    "To get you started, here is a partial implementation where:\n",
    " * the DTMF frequency pairs are available as a dictionary, indexed by the key values\n",
    " * the durations (in seconds) of the tones and the silence gap are also specified.\n",
    "\n",
    "**Exercise: implement a DTMF encoder.** Complete the function below so that it returns the DTMF encoding of a series of key values, passed as a string. The encoding should be padded with 250 milliseconds of silence both at the beginning and at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DTMF_encode(digits: str, Fs=8000) -> np.ndarray: \n",
    "    PADDING_SEC = 0.25\n",
    "    TONE_SEC, SPACE_SEC = 0.2, 0.1\n",
    "    DTMF_FREQS = {\n",
    "        '1': (697, 1209), '2': (697, 1336), '3': (697, 1477),\n",
    "        '4': (770, 1209), '5': (770, 1336), '6': (770, 1477),\n",
    "        '7': (852, 1209), '8': (852, 1336), '9': (852, 1477),\n",
    "        '*': (941, 1209), '0': (941, 1336), '#': (941, 1477),        \n",
    "    }\n",
    "    \n",
    "    # index range for tone intervals\n",
    "    #n = np.arange(...)\n",
    "    \n",
    "    #  output signal, start with initial silence\n",
    "    #x = np.zeros(...))\n",
    "    \n",
    "    for k in digits:\n",
    "        try:\n",
    "            # select the DTMF frequencies\n",
    "            ... \n",
    "            # append tones and space to output\n",
    "            # x = np.r_[ x, ... ]\n",
    "        except KeyError:\n",
    "            print(f'invalid key: {k}')\n",
    "            return None\n",
    "    # append final silence and return\n",
    "    return #..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# SOLUTION:\n",
    "\n",
    "def DTMF_encode(digits: str, Fs=8000) -> np.ndarray: \n",
    "    PADDING_SEC = 0.25\n",
    "    TONE_SEC, SPACE_SEC = 0.2, 0.1\n",
    "    DTMF_FREQS = {\n",
    "        '1': (697, 1209), '2': (697, 1336), '3': (697, 1477),\n",
    "        '4': (770, 1209), '5': (770, 1336), '6': (770, 1477),\n",
    "        '7': (852, 1209), '8': (852, 1336), '9': (852, 1477),\n",
    "        '*': (941, 1209), '0': (941, 1336), '#': (941, 1477),        \n",
    "    }\n",
    "\n",
    "    # index range for tone intervals\n",
    "    n = np.arange(0, int(TONE_SEC * Fs))\n",
    "    # output signal, start with initial silence\n",
    "    x = np.zeros(int(PADDING_SEC * Fs))\n",
    "    \n",
    "    for k in digits:\n",
    "        try:\n",
    "            w_lo, w_hi = 2 * np.pi * np.array(DTMF_FREQS[k]) / Fs \n",
    "            x = np.r_[ x, np.sin(w_lo * n) + np.sin(w_hi * n), np.zeros(int(SPACE_SEC * Fs)) ]\n",
    "        except KeyError:\n",
    "            print(f'invalid key: {k}')\n",
    "            return None\n",
    "    return np.r_[ x, np.zeros(int((PADDING_SEC - SPACE_SEC) * Fs)) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's test it and evaluate it \"by ear\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = DTMF_encode('123##45', Fs=Fs)\n",
    "IPython.display.Audio(x, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Designing a decoder: prep work\n",
    "\n",
    "As is always the case in telecommunication systems, the encoder is the easy part; but now we need to build a decoder. Designing a robust decoder is difficult because there are a lot of things that can degrade the quality of the received signals; for instance:\n",
    " * there will always be some noise in the signal, and sometimes LOTS of noise\n",
    " * the signal could be affected by nonlinear distortion\n",
    " * the durations of tones and gaps can vary a lot\n",
    " * if the intenal clocks at encoder and decoder are running at slightly different speed, the DTMF frequencies will deviate from their nominal values.\n",
    "\n",
    "This week, your take-home exercise is the implementation of a DTMF decoder. To get you started, let's look at the DTMF signal in more detail and see how we can process it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Some helper functions\n",
    "\n",
    "### Something from last week\n",
    "\n",
    "Here is a function that returns the magnitude spectrum of a signal over the positive frequency axis together with the axis labels in Hz; we implemented this in last week's notebook, where you can review the details if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def spectral_power(x: np.ndarray, Fs: float) -> (np.ndarray, np.ndarray):\n",
    "    L = len(x) // 2\n",
    "    return np.linspace(0, Fs/2, L+1), np.abs(np.fft.fft(x)[:L+1]) ** 2 / len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Realistic test files\n",
    "\n",
    "Later in the notebook we will use a set of pre-recorded DTMF test files available in the `data` folder. Here are two helper functions to load and play the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_test_file(filename: str) -> np.ndarray:\n",
    "    # helper function to load a DTMF test file\n",
    "    fs, x = wavfile.read(os.path.join('data', filename))    \n",
    "    # normalize audio data to [-1, 1] if necessary\n",
    "    if x.dtype is np.dtype(np.int16) :   \n",
    "        x = x / 32767.0\n",
    "    return fs, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hear_test_file(basename: str, ix: int):\n",
    "    file = f'{basename}{ix}.wav'\n",
    "    fs, s = read_test_file(file)\n",
    "    print(file)\n",
    "    display(IPython.display.Audio(s, rate=fs, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Time-Frequency Analysis of a DTMF signal\n",
    "\n",
    "A DTMF signal carries information both in time and in frequency: key values are encoded by frequency pairs while the sequence of keys is encoded in time. But this creates a problem: if we look at the spectrum of a DTMF signal we can easily see what keys have been pressed but we can't determine their order or their multiplicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = DTMF_encode('159', Fs)\n",
    "x2 = DTMF_encode('915915', Fs)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(*spectral_power(x1, Fs))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(*spectral_power(x2, Fs));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "On the other hand, if we look at the signals in time we can see the number of key presses and their order but we cannot easily see the DTMF frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(0, len(x1)) / Fs, x1)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(0, len(x2)) / Fs, x2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The solution is **time-frequency** analysis and the most common tool for this is the *spectrogram*. In a spectrogram we split the input signal into shorter segments (or *chunks*) and we compute the magnitude of the DFT for each segment independently. The result is a 2D matrix where each magnitude value is indexed by the chunk number and by the DFT index. To visualize it, the magnitude values are *color-coded* so that low values appear dark and high values appear bright.\n",
    "\n",
    "Here are the spectrograms of the previous signals, and you can see how both the time and the frequency information are clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, s in enumerate([x1, x2]):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    f, t, S = sp.spectrogram(s, Fs)\n",
    "    plt.pcolormesh(t, f, S);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Signal segmentation\n",
    "\n",
    "Our time-frequency analysis suggests that, in order to decode a DTMF signal, we need to isolate each tone interval before we look at its frequency content. Since we know that tone intervals are separated by silent gaps, a simple segmentation strategy is the following:\n",
    " * at each new input sample compute the *instantaneous power* of the signal\n",
    " * look for power level transitions from low (silence gap) to high (tone intervals).\n",
    "\n",
    "To compute the instantaneous power, remember that power is the time average of energy and energy is the sum of the squared samples. With this, the simplest and most common method to compute the instantaneous power is to filter the _squared_ signal with a narrowband lowpass such as a moving average or leaky integrator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inst_pow(x, b, a):\n",
    "    plt.plot(x)\n",
    "    plt.plot(sp.lfilter(b, a, np.abs(x) ** 2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a moving average with 5ms delay\n",
    "M = int(Fs * 0.01)\n",
    "plot_inst_pow(x1, np.ones(M) / M, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using a leaky integrator with the same delay\n",
    "lam = M / (M + 2) \n",
    "plot_inst_pow(x1, 1 - lam, [1, -lam])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Food for thought.**  Now that we have a way to estimate the power of the signal, how can we use this information to segment our audio file? Visually it seems obvious that we need to look for power transitions from low to high and vice-versa but, in practice, to determine if there was a transition we need to use a _threshold_, that is, a reference power value that we compare the current power level to. \n",
    "\n",
    "How can we choose the value of the threshold? Things to think about:\n",
    " * the signal could be noisy, so the power in gaps between tones can be almost as large as the power in tones\n",
    " * in real life, we don't know the \"volume\" of the received signal: attenuation or amplification can arbitrarily change the amplitude of the sinusoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs, s = read_test_file('test3.wav')\n",
    "plot_inst_pow(s, 1 - lam, [1, -lam])\n",
    "display(IPython.display.Audio(s, rate=fs, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## State machines\n",
    "\n",
    "Most digital signal processing applications need to work in real time, that is, they need to process an input stream of samples continuously, one sample at a time. Last week, for instance, we saw how to implement filters as Python *classes* so that a filter could be called repeatedly on individual samples; using classes allowed the filter to preserve the contents of its delay blocks across calls (that is, the filter's internal *state* was persistent).  \n",
    "\n",
    "In more complex systems that implement some decision logic, the processing algorithm needs to behave differently according to the *current* properties of the input; for instance, when decoding DTMF, we want to look at the frequency content in tone intervals but do nothing for the silence gaps. \n",
    "\n",
    "The most common **design pattern** in this case is a *state machine*; every time a new sample arrives:\n",
    " * we first perform the required pre-processing steps (e.g. compute the local energy)\n",
    " * we then apply a different set of processing steps that depend on an internal *state*\n",
    " * finally, we check if we neet to switch to a different state for the next iteration.\n",
    "\n",
    "For example, if we want to isolate the tone segments in a DTMF signal, we can use a machine with three states:\n",
    " 1. waiting for the input power to increase\n",
    " 2. checking that the power increase lasts long enough to indicate a tone\n",
    " 3. waiting for the power to decrease and signal the end of the tone\n",
    "\n",
    "Here is an example that produces a segmentation of a DTMF signal based on a user-defined power threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tone_intervals(x: np.ndarray, t_pow: float, gain: float, Fs=8000) -> (list[tuple[int, int]], np.ndarray):\n",
    "    # gain: gain for leaky integrator to compute power level \n",
    "    # minimum length (ms) for tone detection\n",
    "    MIN_TONE_LEN_MS = 40    \n",
    "    \n",
    "    clips = []\n",
    "    min_tone_len = int(MIN_TONE_LEN_MS * Fs / 1000) \n",
    "    delay = (1 - gain) / gain   # delay of leaky integrator\n",
    "    power = np.zeros(len(x))\n",
    "    \n",
    "    # state machine with three states\n",
    "    WAIT_TONE, CHECK_TONE, WAIT_END = 0, 1, 2\n",
    "    state= WAIT_TONE\n",
    "    \n",
    "    for n in range(0, len(x)):\n",
    "        # compute power with leaky integrator\n",
    "        power[n] = (1 - gain) * power[n-1] + gain * x[n] * x[n]\n",
    "        # check if power is above threshold\n",
    "        power_high = power[n] > t_pow\n",
    "\n",
    "        if state == WAIT_TONE:  # we are waiting for the power to go high\n",
    "            if power_high:\n",
    "                count = 0\n",
    "                state = CHECK_TONE\n",
    "        elif state == CHECK_TONE:  # make sure power stays high before switching\n",
    "            if not power_high:\n",
    "                state = WAIT_TONE  # false alarm: go back to waiting\n",
    "            else:\n",
    "                count += 1\n",
    "                if count > min_tone_len:\n",
    "                    state = WAIT_END  # power was high for more than 40ms, it's a tone\n",
    "        else:  # wait for the end of the tone interval\n",
    "            if power_high:\n",
    "                count += 1\n",
    "            else:\n",
    "                clips.append( (int(n-count-delay), int(n-delay)) )\n",
    "                state = WAIT_TONE\n",
    "    return clips, power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_tone_intervals(x: np.ndarray, t_pow=0.15, gain=0.02, Fs=8000):\n",
    "    tones, power = tone_intervals(x, t_pow, gain, Fs)\n",
    "    plt.plot(x);\n",
    "    plt.plot(power);\n",
    "    plt.axhline(t_pow, color='C4')\n",
    "    for clip in tones:\n",
    "        plt.axvline(clip[0], color='green')        \n",
    "        plt.axvline(clip[1], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_tone_intervals(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Frequency identification\n",
    "\n",
    "Once we have identified where the tone intervals are, we can compute the magnitude DFT of each interval, map the DFT bins to frequency values in Hz, and find the DTMF frequencies that are closest to the peaks of the DFT magnitude. \n",
    "\n",
    "The \"low\" DTMF frequencies are in the 697 Hz to 941 Hz range, while the high frequencies in the 1209 Hz to 1477 Hz range, so we will look for a DFT peak in each of those intervals. For instance, let's look at the first tone, and let's look at the peaks in the DFT: they are very close to the frequencies 697 Hz and 1209 Hz, which correspond to the key \"1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, X = spectral_power(x[slice(*tone_intervals(x, t_pow=0.15, gain=0.02, Fs=8000)[0][0])], Fs)\n",
    "plt.plot(f, X);\n",
    "print(f[np.argsort(X)[-2:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A basic DTMF decoder\n",
    "\n",
    "Using the elements from the previous section, here is a functional DTMF decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DTMF_decode(x: np.ndarray, t_pow=0.15, gain=0.02, Fs=8000) -> list[str]:\n",
    "    # minimum length (ms) for tone detection\n",
    "    MIN_TONE_LEN_MS = 40    \n",
    "    \n",
    "    LO_FREQS = np.array([697.0, 770.0, 852.0, 941.0]) # DTMF rows\n",
    "    HI_FREQS = np.array([1209.0, 1336.0, 1477.0])     # DTMF columns\n",
    "    KEYS = [['1', '2', '3'], \n",
    "            ['4', '5', '6'], \n",
    "            ['7', '8', '9'], \n",
    "            ['*', '0', '#']] \n",
    "\n",
    "    decoded = ''\n",
    "    min_tone_len = int(MIN_TONE_LEN_MS * Fs / 1000) \n",
    "    delay = (1 - gain) / gain \n",
    "    power = 0\n",
    "    \n",
    "    WAIT_TONE, CHECK_TONE, WAIT_END = 0, 1, 2\n",
    "    state= WAIT_TONE\n",
    "    \n",
    "    for n in range(0, len(x)):\n",
    "        power = (1 - gain) * power + gain * x[n] * x[n]\n",
    "        power_high = power > t_pow\n",
    "\n",
    "        if state == WAIT_TONE:  \n",
    "            if power_high:\n",
    "                state, count = CHECK_TONE, 0\n",
    "\n",
    "        elif state == CHECK_TONE:  \n",
    "            if power_high:\n",
    "                count += 1\n",
    "                state = WAIT_END if count > min_tone_len else CHECK_TONE\n",
    "            else:\n",
    "                state = WAIT_TONE  \n",
    "     \n",
    "        else:  # WAIT_END\n",
    "            if power_high:\n",
    "                count += 1\n",
    "            else:\n",
    "                # compute tone magnitude spectrum\n",
    "                X = np.abs(np.fft.fft(x[slice(int(n-count-delay), int(n-delay))]))\n",
    "                N = len(X)\n",
    "        \n",
    "                k = KEYS\n",
    "                for freqs in ([LO_FREQS, HI_FREQS]):\n",
    "                    # map frequency range to DFT indexes\n",
    "                    r_min, r_max = int(N / Fs * np.min(freqs - 100)), int(N / Fs * np.max(freqs + 100))\n",
    "                    # find frequency peak\n",
    "                    ix = r_min + np.argmax(X[slice(r_min, r_max)])\n",
    "                    # find closest DTMF frequency within range\n",
    "                    f_ix = int(np.argmin(np.abs(freqs - Fs * ix / N)))\n",
    "                    # first iteration extract row, second iteration extract column\n",
    "                    k = k[f_ix]\n",
    "        \n",
    "                decoded += k                 \n",
    "                state = WAIT_TONE\n",
    "    return decoded            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works very well on clean signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = '123##45'\n",
    "k = DTMF_decode(DTMF_encode(keys, Fs=Fs), Fs=Fs)\n",
    "print('good job!' if k == keys else k + '  ** oups, try again!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## But life is not so simple...\n",
    "\n",
    "Although the decoder works on a clean, synthetic DTMF signal, in the real world it will have to deal with problems such as noise, attenuation, frequency drifts, and varying pulse lengths. A few test cases illustrating these impairments are available in the `data` directory of this notebook.\n",
    "\n",
    "We can test our basic decoder using the following script and see how many it gets right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#for n in range(0, 14):\n",
    "#    hear_test_file('test', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_decoder(basename: str, decoder, **kwargs):\n",
    "    # decode all test files with the same basename and check the results\n",
    "    with open(os.path.join('data', f'{basename}.log'), 'r') as csvfile:\n",
    "        test_files = csv.DictReader(csvfile, fieldnames=['ix', 'keys'], delimiter=';')\n",
    "        total, ok = 0, 0\n",
    "        for file in test_files:\n",
    "            fs, s = read_test_file(f'{basename}{file[\"ix\"]}.wav')\n",
    "            total += 1\n",
    "            res = decoder(s, **kwargs)\n",
    "            if str(res).strip() == str(file[\"keys\"]).strip():\n",
    "                flag = 'OK'\n",
    "                ok += 1\n",
    "            else:\n",
    "                flag = 'ERROR'\n",
    "            print(f'{file[\"ix\"]}: {flag}   (encoded: {file[\"keys\"]}, decoded: {res})')\n",
    "    print(f'\\nYou got {ok} out of {total} correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_decoder('test', DTMF_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Why does it fail?\n",
    "\n",
    "Decoding mistakes are due essentially to signal segmentation errors. For instance, in the following example, some tones are missed while others are split into multiple clips, leading to both missed digits and duplicate digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs, noisy = read_test_file('test3.wav')\n",
    "IPython.display.Audio(noisy, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DTMF_decode(noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is apparent if we plot the segmentation results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tone_intervals(noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The segmentation algorithm is parametrized via:\n",
    " * the gain of the leaky integrator, which trades off smoothing power with delay\n",
    " * the threshold for the power level\n",
    " \n",
    "We could try to play with these two parameters and, with patience and some luck, we could find a pair of values that \"fix\" the decoder _for this particular case_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    't_pow': .146,\n",
    "    'gain': .006\n",
    "}\n",
    "show_tone_intervals(noisy, **params, Fs=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTMF_decode(noisy, **params, Fs=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values we just used, however, do not \"magically\" work for all test files (although they make things better). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_decoder('test', DTMF_decode, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A robust DTMF decoder\n",
    "\n",
    "We will now develop a more robust DTMF decoder that does not rely on hard-coded thresholds. We want to estimate and adapt the segmentation thresholds from the input signal so that we can handle both additive noise and unknown attenuation. \n",
    "\n",
    "The key idea is to separate the power associated to the DTMF tones from the total power of the signal; if we move to the frequency domain, we know exactly _where_ to look for tone energy in the spectrum since there are only 7 possible DTMF tone frequencies. If the signal is corrupted by additive white noise, whose power spectral density is more or less flat:\n",
    "\n",
    " * when there is no tone, the average energy will be more or less the same tone and non-tone frequencies;\n",
    " * when a tone appears, only the tone energy should increase.\n",
    "\n",
    "The trick is to compute the tone detection threshold from the signal's tone and non-tone power levels as estimated from the spectral energy distribution. To do so, we will move to the frequency domain by taking the DFT of successive chunks of the signal. The first question, therefore, is finding a good value for the size of the chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal DFT length\n",
    "\n",
    "An $N$-point DFT has the following properties:\n",
    " * each DFT coeficient is associated to a center frequency $\\omega_k = (2\\pi/N)k$\n",
    " * the frequency resolution, that is, the difference between adjacent bin frequencies, is $\\Delta_N = 2\\pi/N$\n",
    " * each DFT coefficient covers the frequency interval $[\\omega_k - \\Delta_N/2, \\omega_k + \\Delta_N/2]$\n",
    "\n",
    "If we know the sampling frequency, \n",
    " * the frequency resolution is $\\Delta_f = F_s/N$ Hz\n",
    " * each DFT coefficient corresponds to the interval $[(F_s/N)(k-1/2), (F_s/N)(k+1/2)]$ Hz.\n",
    "\n",
    "This means that if we take $N$ samples of a signal containing two sinusoids, we will be able to see two distinct spectral lines only if the DFT frequency resolution is smaller than the frequency difference between the sinusoid. By \"distinct\", we mean that there is at least one DFT bin separating the lines. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, w = 60, 0.3 * np.pi \n",
    "\n",
    "D, n = 2 * np.pi / N, np.arange(0, N)\n",
    "for i in [1, 2]:\n",
    "    plt.subplot(1,2,i)\n",
    "    plt.stem(*spectral_power(np.sin(w * n) + np.sin((w + i * D) * n), N));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the decoder needs to locate the spectral peaks corresponding to the DTMF frequencies, we would like to use a DFT size such that \n",
    "  * neighboring DTMF frequencies always appear as distinct lines\n",
    "  * the DTMF frequencies fall as close as possible to one of the DFT center frequency values (in Hz)\n",
    "\n",
    "With respect to the first condition, the smallest distance between DTMF frequencies is 73 Hz so the DFT size should be at least 14 ms; at the same time, the DFT size cannot be too large and certainly it cannot be larger than 40 ms, the minimum tone length allowed by the DTMF standard.\n",
    "\n",
    "The following function computes the optimal DFT lenght for a given sampling frequency and a maximum size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def optimal_DFT_size(max_len_ms: float, Fs: float) -> (int, np.ndarray):\n",
    "    DTMF_FREQS = np.array((697, 770, 852, 941, 1209, 1336, 1477))\n",
    "\n",
    "    # minimum DFT size to guarantee frequency separation\n",
    "    min_delta = np.min(np.abs(DTMF_FREQS[1:] - DTMF_FREQS[:-1]))\n",
    "    min_len = int(Fs / min_delta)\n",
    "    max_len = int(max_len_ms * Fs / 1000)\n",
    "\n",
    "    ret = (0, [])\n",
    "    min_err = 1e100\n",
    "    for dft_len in range(min_len, max_len + 1):\n",
    "        # compute the difference between nominal DTMF frequencies and closest DFT center bin frequencies\n",
    "        bins = np.round(DTMF_FREQS / Fs * dft_len).astype(int)\n",
    "        offsets = bins * Fs / dft_len - DTMF_FREQS\n",
    "        # Mean Square Error for offsets\n",
    "        err = np.sqrt(np.sum(offsets ** 2) / Fs * dft_len)\n",
    "        if err < min_err:\n",
    "            min_err = err\n",
    "            ret = (dft_len, bins)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the optimal size is not the maximum size, as shown in the following plot. In particular, for $F_s = 8000$, a 40 ms DFT window is 320 samples long; yet, the optimal choice is a 299-sample DFT because it minimizes the approximation error for the DTMF frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.arange(15, 40)\n",
    "plt.plot(k, [optimal_DFT_size(t, Fs)[0] for t in k]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_DFT_size(40, Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window\n",
    "\n",
    "Once we have chosen the DFT size, another way to make the decoder more robust is to use overlapping windows, that is, shift the analysis window by a fraction of the window length. The amount of displacement is called _stride_ and we will choose 5 ms, that is, about 1/8 of the analysis window. The redundance of an overlapped analysis provides better time resolution and noise immunity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone and non-tone energy\n",
    "\n",
    "At each time $n$ we compute $X_n[k]$, the DFT of the data vector $[x[n-N+1], \\ldots, x[n]]$. There are seven possible DTMF frequency values, $f_0$ to $f_6$, and let $k_i$ be the DFT bin corresponding to $f_i$; we compute the spectral energy for $f_i$ as the average energy over three neighboring DFT bins:\n",
    "\n",
    "$$\n",
    "    E(i; n) = \\frac{1}{3}\\sum_{m=-1}^{1}|X_n[k_i + m]|.\n",
    "$$\n",
    "\n",
    "Conversely, the non-tone energy will be the averaged energy over all DFT bins not used for tone energy.\n",
    "\n",
    "Both tone and non-tone energies will be time-averaged using leaky integrators; since the estimated average tone energy should be estimated only when a tone is present, we stabilize the estimation process by reducing the leaky integrator gain when we assume there is no tone in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key decoding\n",
    "\n",
    "Once we have detected that a tone is present, the spectral energy for the 7 DTMF frequencies is accumulated for _all_ 7 frequencies in a 7-bin histogram. When we detect the end of a tone interval, we determine the two largest histogram values within the low and high DTMF frequency ranges to decode the key value. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def freqs2key(bin_energy: np.ndarray) -> (int, str):\n",
    "    # the function takes a vector of accumulated energy values for the DTMF frequency \"slots\"\n",
    "    #  and returns the key value corresponding to the largest lo and hi values\n",
    "    DTMF_KEYS = '123456789*0#'\n",
    "    ix = 3 * np.argmax(bin_energy[:4]) + np.argmax(bin_energy[4:])\n",
    "    return DTMF_KEYS[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def DTMF_dplus(x: np.ndarray, Fs=8000, debug=False) -> list[str]:\n",
    "    # step for analysis windows\n",
    "    STRIDE_MS = 5\n",
    "    # gains for leaky integrators\n",
    "    GAIN_SLOW, GAIN_FAST = 0.005, 0.02\n",
    "\n",
    "    # find optimal DFT size and tone bins (max len 40 ms)\n",
    "    M, bins = optimal_DFT_size(40, Fs)\n",
    "    # binary mask for all non-tone frequency bins in DFT\n",
    "    non_tone_bins = np.full(M, True)\n",
    "    non_tone_bins[bins] = non_tone_bins[bins-1] = non_tone_bins[bins+1] = False\n",
    "    \n",
    "    stride = int(STRIDE_MS * Fs / 1000)\n",
    "    min_tone_len = int(40 / STRIDE_MS)\n",
    "    min_gap_len = int(20 / STRIDE_MS)\n",
    "        \n",
    "    # initial estimate for noise floor (assuming leading silence)\n",
    "    #  (we \"cheat\" a bit by looking at future data, but we could obtain the same\n",
    "    #    result using an extra state in the processing state machine)\n",
    "    nont_level = np.sum(x[:M] ** 2)\n",
    "    # initial estimate for tone energy\n",
    "    tone_level = nont_level * 2\n",
    "    n_gain, t_gain = GAIN_FAST, GAIN_SLOW\n",
    "\n",
    "    # debug data\n",
    "    steps = len(x) // stride + 1\n",
    "    debug_data = {\n",
    "        'ept': np.zeros((steps, len(bins))),\n",
    "        'tae': np.zeros(steps),\n",
    "        'nae': np.zeros(steps),\n",
    "        'avg': np.zeros((steps, 3))\n",
    "                        }\n",
    "    # state machine\n",
    "    WAIT_TONE, CHECK_TONE, WAIT_GAP, CHECK_GAP = 0, 1, 2, 3\n",
    "    count, state = 0, WAIT_TONE\n",
    "    decoded = ''\n",
    "\n",
    "    for n in range(0, len(x)-M, stride):\n",
    "        spectral_energy = np.abs(np.fft.fft(x[n:n+M])) ** 2\n",
    "        # energy for each tone frequency (avg of center bin and two neighboring bins)\n",
    "        #  this is a length-7 vector, one element per DTMF frequency value\n",
    "        energy_per_tone = (spectral_energy[bins] + spectral_energy[bins-1] + spectral_energy[bins+1]) / 3\n",
    "        # avg energy over all tone and non-ton bins\n",
    "        mean_tone_erg = np.mean(energy_per_tone)\n",
    "        mean_nont_erg = np.mean(spectral_energy[non_tone_bins])\n",
    "\n",
    "        # time averaging of energy levels\n",
    "        tone_level = (1 - t_gain) * tone_level + t_gain * mean_tone_erg\n",
    "        nont_level = (1 - n_gain) * nont_level + n_gain * mean_nont_erg\n",
    "        \n",
    "        # check if current mean tone energy is 1/3 of the way up between non-tone and tone energy levels\n",
    "        threshold = nont_level + (tone_level - nont_level) * 0.3\n",
    "        tone_present = mean_tone_erg > threshold\n",
    "        \n",
    "        if state == WAIT_TONE:  \n",
    "            if tone_present:\n",
    "                tone_energy_histogram = energy_per_tone\n",
    "                t_gain = GAIN_FAST  # update tone level quicker now\n",
    "                count, state = 1, CHECK_TONE\n",
    "        \n",
    "        elif state == CHECK_TONE:  \n",
    "            if tone_present:\n",
    "                tone_energy_histogram += energy_per_tone\n",
    "                count += 1\n",
    "                if count > min_tone_len:\n",
    "                    state = WAIT_GAP \n",
    "            else:\n",
    "                # false alarm, let's go back to waiting\n",
    "                t_gain = GAIN_SLOW\n",
    "                state = WAIT_TONE  \n",
    "        \n",
    "        elif state == WAIT_GAP: \n",
    "            if tone_present:\n",
    "                tone_energy_histogram += energy_per_tone\n",
    "            else:\n",
    "                decoded += freqs2key(tone_energy_histogram)\n",
    "                t_gain = GAIN_SLOW\n",
    "                count, state = 1, CHECK_GAP\n",
    "        \n",
    "        elif state == CHECK_GAP: \n",
    "            if tone_present:\n",
    "                count = 0\n",
    "            else:\n",
    "                count += 1\n",
    "                if count > min_gap_len:\n",
    "                    state = WAIT_TONE\n",
    "                    \n",
    "        else:\n",
    "            raise \"non-existing state\"\n",
    "        \n",
    "        ix = n // stride\n",
    "        debug_data['ept'][ix] = energy_per_tone\n",
    "        debug_data['tae'][ix] = mean_tone_erg\n",
    "        debug_data['nae'][ix] = mean_nont_erg\n",
    "        debug_data['avg'][ix] = [tone_level, nont_level, threshold]       \n",
    "\n",
    "    if debug:\n",
    "        plt.plot(debug_data['ept']);\n",
    "        plt.plot(debug_data['tae'], 'C0', label=\"avg tone energy (dash: trend)\");    \n",
    "        plt.plot(debug_data['avg'][:,0], 'C0:');\n",
    "        plt.plot(debug_data['nae'], 'C1', label=\"avg non-tone energy (dash: trend)\");    \n",
    "        plt.plot(debug_data['avg'][:,1], 'C1:');\n",
    "        plt.plot(debug_data['avg'][:,2], 'C3:', label=\"threshold\");\n",
    "        plt.legend()\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_decoder('test', DTMF_dplus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also look at the various signals in the decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, noisy = read_test_file('test4.wav')\n",
    "DTMF_dplus(noisy, Fs=fs, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(noisy);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
